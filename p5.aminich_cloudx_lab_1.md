aws ec2 create-key-pair \
    --key-name aminich-key-pair \
    --key-type rsa \
    --query "KeyMaterial" \
    --output text > aminich-key-pair.pem
    
    
    
    
    
    
    
    
Tags:
- Project=CloudX
- part=aminich_cloudx_lab_1  
MyIps:
- 87.228.191.50
- 195.56.119.212



### Create Network stack
#### Create network stack for your infrastructure with the following resources:
- VPC:
	name=cloudx, cidr=10.10.0.0/16, enable_dns_support=true, enable_dns_hostnames=true

- 3 x Public subnets:
	name=public_a, cidr=10.10.1.0/24, az=a
	name=public_b, cidr=10.10.2.0/24, az=b
	name=public_c, cidr=10.10.3.0/24, az=c


- Internet gateway (name=cloudx-igw) and attach it to appropriate VPC
- Routing table to bind Internet gateway with the Public subnets (name=public_rt)

### Create security groups
#### Create the following security groups:

- name=bastion, description="allows access to bastion":
	!!!ingress rule_1: port=22, source={your_ip}, protocol=tcp  
	egress rule_1: allows any destination

- name=ec2_pool, description="allows access to ec2 instances":
	ingress rule_1: port=22, source_security_group={bastion}, protocol=tcp
	ingress rule_2: port=2049, source={vpc_cidr} 10.10.0.0./16, protocol=tcp
	ingress rule_3: port=2368, source_security_group={alb}, protocol=tcp
	egress rule_1: allows any destination

- name=alb, description="allows access to alb":
	!!!ingress rule_1: port=80, source={your_ip}, protocol=tcp
	egress rule_1: port=any, source_security_group={ec2_pool}, protocol=any

- name=efs, description="defines access to efs mount points":
	ingress rule_1: port=2049, source_security_group={ec2_pool}, protocol=tcp
	egress rule_1: allows any destination to {vpc_cidr} 10.10.0.0./16

### Create SSH Key pair
#### Create custom ssh key-pair to access your ec2 instances:(refer to this document)
Uppload it to AWS with name=ghost-ec2-pool

### Create IAM role
#### Create IAM Role and asosiated IAM Role profile (name=ghost_app) with the following permissions:
```
"ec2:Describe*",
"elasticfilesystem:DescribeFileSystems",
"elasticfilesystem:ClientMount",
"elasticfilesystem:ClientWrite"
```
This IAM role now provides EC2 instances with access to the services. For test purposes it acceptable to allow "any" resource access. You would consider to restrict each service in policy with resource arn(using separate statement for each service) in the real environments.

### Create Elastic File System
- Create EFS file system resource(name=ghost_content)
- Create EFS mount targets for each AZ and assign them with {efs} security group

### Create Application load balancer
cloudx-lb
- Create Application Load Balancer with 1 target group:
	target group 1: name=ghost-ec2,port=2368,protocol="HTTP"
- Create ALB listener: port=80,protocol="HTTP", avalability zone=a,b,c
- Edit ALB listener rule: action type = "forward",target_group_1_weight=100


Create Launch Template
In this task you have to author launch tempalate to run Ghost application with UserData script on instance start up. Use Amazon Linux 2 as the base image.
Start up script should do the following:

Install pre-requirements
Install, configure and run Ghost application


  Script example(click to expand):
```bash
#!/bin/bash -xe

exec > >(tee /var/log/cloud-init-output.log|logger -t user-data -s 2>/dev/console) 2>&1

REGION=$(/usr/bin/curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone | sed 's/[a-z]$//')
EFS_ID=$(aws efs describe-file-systems --query 'FileSystems[?Name==`ghost_content`].FileSystemId' --region $REGION --output text)

### Install pre-reqs
curl -sL https://rpm.nodesource.com/setup_14.x | sudo bash -
yum install -y nodejs amazon-efs-utils
npm install ghost-cli@latest -g

adduser ghost_user
usermod -aG wheel ghost_user
cd /home/ghost_user/

sudo -u ghost_user ghost install local

### EFS mount
mkdir -p /home/ghost_user/ghost/content
mount -t efs -o tls $EFS_ID:/ /home/ghost_user/ghost/content

cat << EOF > config.development.json

{
  "url": "http://${LB_DNS_NAME}",
  "server": {
    "port": 2368,
    "host": "0.0.0.0"
  },
  "database": {
    "client": "sqlite3",
    "connection": {
      "filename": "/home/ghost/content/data/ghost-local.db"
    }
  },
  "mail": {
    "transport": "Direct"
  },
  "logging": {
    "transports": [
      "file",
      "stdout"
    ]
  },
  "process": "local",
  "paths": {
    "contentPath": "/home/ghost/content"
  }
}
EOF

sudo -u ghost ghost stop
sudo -u ghost ghost start
```

You can refer to the application documentation
Ð¡reate Launch Templpate:

name=ghost, instance_type=t2.micro, security_group={ec2_pool}, key_name={ghost-ec2-pool}, userdata={your_startup_script}

To check script you can run single EC2 instance using Launch Template. Don't forget to remove it after testing.
Hint: you can use cloud-init log to examine userData scipt output(/var/log/cloud-init-output.log)


### Create Auto-scaling group
- Create Auto-scaling group and assign it with Launch Template from step 5:
	name=ghost_ec2_pool
	avalability zone=a,b,c
	Attach ASG with {ghost-ec2} target group

### Create Bastion

Create bastion host:
- Create EC2 instance:
	- name: bastion
	- instance_type: t2.micro
	- AMI: Amazon Linux 2
	- associate_public_ip_address: true
	- security_group: {bastion}
	- key_name: {ghost-ec2-pool}
- Configure your ssh_config
- Try to connect to your ec2_pool instance by ssh
